---
phase: 01-daily-briefing-refactor
plan: 05
type: execute
wave: 3
depends_on: ["01-03", "01-04"]
files_modified: [".planning/phases/01-daily-briefing-refactor/01-05-SUMMARY.md", "migration-plan.md"]
autonomous: false
user_setup:
  - service: n8n
    why: "Deploy and activate new workflow, monitor migration"
    dashboard_config:
      - task: "Monitor new workflow execution"
        location: "n8n UI → Executions tab"
      - task: "Verify user notifications"
        location: "ntfy.sh topics or monitoring tool"
  - service: supabase
    why: "Monitor query performance during migration"
    dashboard_config:
      - task: "Check query performance"
        location: "Supabase Dashboard → Database → Logs"
---

<objective>
Execute comprehensive testing and safe migration from hardcoded daily briefing workflow to new dynamic architecture.

Purpose: Validate that the new dynamic workflow produces identical results to the existing system while eliminating hardcoded user chains, then safely migrate with zero downtime.

Output: Complete migration documentation, test results, and rollback procedures for safe deployment.
</objective>

<execution_context>
@~/.config/opencode/get-shit-done/workflows/execute-plan.md
@~/.config/opencode/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PHASE_ANALYSIS.md
@.planning/phases/01-daily-briefing-refactor/01-03-SUMMARY.md
@.planning/phases/01-daily-briefing-refactor/01-04-SUMMARY.md
@CLAUDE.md

# Migration Requirements
- Zero downtime during transition
- Maintain existing notification timing
- Preserve all user preferences
- Enable instant rollback if issues arise
- Validate output quality consistency

# Current vs New Workflow Comparison
- Current: vyxpQ5_WIpneleTOCUKRX (30+ nodes, hardcoded users)
- New: dynamic-daily-briefing.json (constant node count, dynamic users)
- Both: Same notification times, same LLM model, same user experience

# Testing Strategy
- Parallel execution comparison
- Output quality validation
- Performance benchmarking
- Error handling verification
</context>

<tasks>

<task type="auto">
  <name>Create Parallel Testing Environment</name>
  <files>migration-plan.md</files>
  <action>
1. Deploy new dynamic workflow in parallel mode:
   - Import workflows/dynamic-daily-briefing.json to n8n
   - Configure with Manual Trigger only (disable Schedule initially)
   - Configure with Webhook Trigger for testing
   - Keep existing workflow active and scheduled

2. Create test data and validation framework:
   - Identify test users representing different scenarios
   - Document expected briefing content per user
   - Create comparison checklist for output validation
   - Set up monitoring for both workflows

3. Create parallel testing protocol:
   - Manual execution of new workflow for test users
   - Compare outputs with existing scheduled briefings
   - Document any differences in content, format, timing
   - Validate notification delivery to correct channels

4. Set up performance monitoring:
   - Track execution time per user for both workflows
   - Monitor database query performance
   - Measure LLM API usage and response times
   - Check memory and resource usage

5. Create validation criteria checklist:
   - Content accuracy: Same tasks, same categorization
   - Format consistency: Same length, same tone, same structure
   - Delivery reliability: Same notification channels, same timing
   - Performance: Equal or better response times
   - Error handling: Graceful failure recovery

6. Document baseline metrics from existing workflow:
   - Average execution time per user
   - Total execution time for all users
   - Success/failure rates
   - Resource usage patterns
</action>
  <verify>Deploy new workflow in parallel mode and confirm it doesn't interfere with existing scheduled execution</verify>
  <done>Parallel testing environment established with comprehensive validation framework</done>
</task>

<task type="auto">
  <name>Execute Comprehensive Output Validation</name>
  <files>.planning/phases/01-daily-briefing-refactor/01-05-SUMMARY.md</files>
  <action>
1. Execute test briefings for diverse user scenarios:
   - User with many overdue tasks
   - User with only high-priority items
   - User with recently completed tasks
   - User with no active tasks
   - User with special notification preferences

2. Compare outputs side-by-side:
   - Run new workflow manually for test users
   - Wait for next scheduled execution of old workflow
   - Compare briefing content for each test user
   - Document any differences in categorization or formatting

3. Validate notification delivery:
   - Verify new workflow sends to correct ntfy topics
   - Check message formatting and priority levels
   - Test email fallback scenarios
   - Confirm delivery timing matches expectations

4. Test on-demand briefing integration:
   - Use chat interface to request briefings
   - Verify "Today's briefing" and similar triggers work
   - Test with authenticated users only
   - Validate response formatting for chat

5. Performance benchmarking:
   - Measure execution time per user in new workflow
   - Compare with baseline from existing workflow
   - Check database query performance under load
   - Verify LLM API response times are consistent

6. Error handling validation:
   - Test with invalid user scenarios
   - Simulate ntfy notification failures
   - Test LLM service unavailability
   - Verify graceful error handling and recovery

7. Document all validation results:
   - Content comparison matrix
   - Performance benchmark tables
   - Error handling test results
   - User experience validation findings
</action>
  <verify>Complete all test scenarios and document that new workflow produces equivalent or better results than existing system</verify>
  <done>Comprehensive validation completed confirming new workflow meets all functional and performance requirements</done>
</task>

<task type="checkpoint:human-verify">
  <name>Migration Approval Checkpoint</name>
  <what-built>Complete parallel testing results showing new dynamic workflow produces identical briefings to existing hardcoded system</what-built>
  <how-to-verify>
1. Review validation results in 01-05-SUMMARY.md
2. Check content comparison matrix for briefing equivalence
3. Verify performance benchmarks meet or exceed existing system
4. Confirm notification delivery testing was successful
5. Validate error handling scenarios work correctly
6. Ensure on-demand chat integration is functioning properly

Review the migration-plan.md for:
- Complete rollback procedures
- Step-by-step migration timeline
- Risk mitigation strategies
- Monitoring setup for post-migration

If all validation passes and risks are acceptable, approve migration. If any issues found, address them before proceeding.
</how-to-verify>
  <resume-signal>Type "approved" to proceed with migration or describe issues that need to be addressed</resume-signal>
</task>

<task type="auto">
  <name>Execute Migration with Zero Downtime</name>
  <files>migration-plan.md</files>
  <action>
1. Prepare migration execution:
   - Set up monitoring dashboard for both workflows
   - Prepare backup configurations
   - Document rollback trigger conditions
   - Coordinate timing with user schedule

2. Execute migration steps:
   - Step 1: Disable Schedule Trigger on existing workflow (vyxpQ5_WIpneleTOCUKRX)
   - Step 2: Enable Schedule Trigger on new workflow (same time: 8 AM)
   - Step 3: Update Web API Router to use new daily briefing tool
   - Step 4: Monitor first scheduled execution of new workflow
   - Step 5: Verify all users receive their briefings correctly

3. Post-migration monitoring:
   - Watch execution logs for any failures
   - Monitor notification delivery success rates
   - Track user feedback or complaints
   - Check system resource usage patterns

4. Validation of complete migration:
   - Confirm no missed briefings after migration
   - Verify all scheduled executions run successfully
   - Test on-demand briefing requests continue working
   - Check performance remains within acceptable limits

5. Cleanup and optimization:
   - Archive old workflow configuration
   - Update documentation references
   - Remove any temporary testing configurations
   - Optimize new workflow based on observed performance

6. Document migration results:
   - Record actual migration timeline
   - Document any issues encountered and resolutions
   - Capture performance improvements achieved
   - Update system documentation with new architecture

7. Prepare rollback documentation (for future reference):
   - Document what worked well
   - Note any lessons learned
   - Update migration procedures based on experience
</action>
  <verify>Monitor migration execution and confirm all users receive their briefings as scheduled with no service interruption</verify>
  <done>Migration completed successfully with zero downtime and improved system architecture</done>
</task>

</tasks>

<verification>
- Parallel testing confirms new workflow produces identical briefings to existing system
- Performance benchmarks show new workflow meets or exceeds existing performance
- All test scenarios (various user types, error conditions) pass validation
- Migration executes with zero downtime and no missed briefings
- Post-migration monitoring shows stable operation
- On-demand briefing integration works correctly from chat interface
- All user preferences and notification settings preserved
- System scalability improved with dynamic user iteration
</verification>

<success_criteria>
- Comprehensive test validation confirms equivalence with existing system
- Migration executed with zero downtime and no service interruption
- All users continue receiving scheduled briefings at expected times
- On-demand briefing capability successfully integrated into chat interface
- System scalability improved from 5 hardcoded users to unlimited dynamic users
- Node count reduced from 30+ to constant ~15 nodes regardless of user count
- Performance maintained or improved with optimized database queries
- Robust error handling and monitoring in place for ongoing operations
- Complete documentation and rollback procedures established
</success_criteria>

<output>
After completion, create `.planning/phases/01-daily-briefing-refactor/01-05-SUMMARY.md` documenting:
1. Parallel testing methodology and comprehensive validation results
2. Performance benchmark comparisons and optimization outcomes
3. Migration execution timeline and zero-downtime verification
4. Post-migration monitoring results and system stability validation
5. Architecture improvements achieved (scalability, maintainability)
6. Lessons learned and best practices for future migrations
7. Final rollback procedures and ongoing maintenance guidelines

Update migration-plan.md with actual execution results and any deviations from planned procedures.
</output>